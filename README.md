# Understanding-driving-distractions-A-multimodal-analysis-on-distraction-characterization
Distracted driving is a leading cause of accidents worldwide. The tasks of distraction detection and recognition have been traditionally
addressed as computer vision problems. However, distracted behaviors are not always expressed in a visually observable way.
In this work, we introduce a novel multimodal dataset of distracted driver behaviors, consisting of data collected using twelve information
channels coming from visual, acoustic, near-infrared, thermal, physiological and linguistic modalities. The data were collected
from 45 subjects while being exposed to four different distractions (three cognitive and one physical). For the purposes of this paper,
we experiment with visual and physiological information and explore the potential of multimodal modeling for distraction recognition.
In addition, we analyze the value of different modalities by identifying specific visual and physiological groups of features
that contribute the most to distraction characterization. Our results highlight the advantage of multimodal representations and
reveal valuable insights for the role played by the two modalities on identifying different types of driving distractions.
